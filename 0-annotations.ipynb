{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3effd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca807dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./dset\"\n",
    "DERIVATIVES_DIR = \"./derivatives\"\n",
    "ANNOT_DIR = Path(\"dset/annotations\")\n",
    "OUT_DIR = Path(\"derivatives/annotations\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bd745e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_annotation_files(annotation_dir: Path):\n",
    "    pattern = re.compile(r\"^(S\\d+E\\d+R\\d+)_([A-Za-z]{2})\\.csv$\")\n",
    "    groups = {}\n",
    "    for p in sorted(annotation_dir.iterdir()):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        m = pattern.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        prefix = m.group(1)\n",
    "        annot = m.group(2)\n",
    "        groups.setdefault(prefix, []).append((annot, p))\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02935427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_columns(df: pd.DataFrame):\n",
    "    # detect index column\n",
    "    if \"index\" in df.columns:\n",
    "        idx_col = \"index\"\n",
    "    else:\n",
    "        # fallback: first column\n",
    "        idx_col = df.columns[0]\n",
    "\n",
    "    # detect valence and arousal columns (case-insensitive)\n",
    "    val_cols = [c for c in df.columns if \"valence\" in c.lower()]\n",
    "    aro_cols = [c for c in df.columns if \"arousal\" in c.lower()]\n",
    "\n",
    "    val_col = val_cols[0] if val_cols else None\n",
    "    aro_col = aro_cols[0] if aro_cols else None\n",
    "    return idx_col, val_col, aro_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae54c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_group(prefix, files):\n",
    "    # files: list of (annotator_code, Path)\n",
    "    \n",
    "    # Skip if less than 2 files\n",
    "    if len(files) < 2:\n",
    "        print(f\"Skipping {prefix}: need at least 2 files, found {len(files)}\")\n",
    "        return None\n",
    "    \n",
    "    dfs = []\n",
    "    renamed = []\n",
    "    valid_count = 0  # Track valid files separately from loop index\n",
    "    \n",
    "    for annot, path in sorted(files):\n",
    "        df = pd.read_csv(path)\n",
    "        idx_col, val_col, aro_col = detect_columns(df)\n",
    "        if val_col is None or aro_col is None:\n",
    "            print(f\"Skipping {path.name}: could not find valence/arousal columns\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        # create minimal df using valid_count for consistent numbering\n",
    "        valid_count += 1\n",
    "        out = pd.DataFrame()\n",
    "        out[\"index\"] = df[idx_col]\n",
    "        out[f\"valence_{valid_count}\"] = df[val_col].values\n",
    "        out[f\"arousal_{valid_count}\"] = df[aro_col].values\n",
    "        dfs.append(out)\n",
    "        renamed.append((annot, f\"valence_{valid_count}\", f\"arousal_{valid_count}\"))\n",
    "\n",
    "    if len(dfs) < 2:\n",
    "        print(f\"Skipping {prefix}: need at least 2 valid files after filtering, found {len(dfs)}\")\n",
    "        return None\n",
    "\n",
    "    # merge on index\n",
    "    merged = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        merged = pd.merge(merged, d, on=\"index\", how=\"outer\")\n",
    "\n",
    "    # sort by index if numeric\n",
    "    try:\n",
    "        merged[\"index\"] = pd.to_numeric(merged[\"index\"])\n",
    "        merged = merged.sort_values(\"index\").reset_index(drop=True)\n",
    "    except Exception:\n",
    "        merged = merged.reset_index(drop=True)\n",
    "\n",
    "    # Reorder columns: index, all valence_*, then all arousal_*\n",
    "    val_cols = [c for c in merged.columns if c.startswith(\"valence_\")]\n",
    "    aro_cols = [c for c in merged.columns if c.startswith(\"arousal_\")]\n",
    "\n",
    "    def _num_suffix(colname):\n",
    "        parts = colname.split(\"_\")\n",
    "        try:\n",
    "            return int(parts[-1])\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    val_cols = sorted(val_cols, key=_num_suffix)\n",
    "    aro_cols = sorted(aro_cols, key=_num_suffix)\n",
    "\n",
    "    new_cols = [\"index\"] + val_cols + aro_cols\n",
    "    # keep any unexpected columns at the end (shouldn't typically occur)\n",
    "    tail = [c for c in merged.columns if c not in new_cols]\n",
    "    merged = merged[new_cols + tail]\n",
    "\n",
    "    return merged, renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f8ec108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote derivatives/annotations/S01E01R01.csv (2 files -> 334 rows)\n",
      "Wrote derivatives/annotations/S01E01R02.csv (2 files -> 276 rows)\n",
      "Wrote derivatives/annotations/S01E01R03.csv (2 files -> 275 rows)\n",
      "Skipping S01E01R04: need at least 2 files, found 1\n",
      "No valid files for S01E01R04\n",
      "Skipping S01E01R05: need at least 2 files, found 1\n",
      "No valid files for S01E01R05\n",
      "Skipping S01E01R06: need at least 2 files, found 1\n",
      "No valid files for S01E01R06\n",
      "Wrote derivatives/annotations/S01E02R01.csv (2 files -> 313 rows)\n",
      "Wrote derivatives/annotations/S01E02R02.csv (8 files -> 250 rows)\n",
      "Wrote derivatives/annotations/S01E02R03.csv (2 files -> 362 rows)\n",
      "Wrote derivatives/annotations/S01E02R04.csv (2 files -> 354 rows)\n",
      "Wrote derivatives/annotations/S01E02R05.csv (2 files -> 295 rows)\n",
      "Wrote derivatives/annotations/S01E02R06.csv (2 files -> 218 rows)\n",
      "Wrote derivatives/annotations/S01E02R07.csv (2 files -> 294 rows)\n",
      "Wrote derivatives/annotations/S01E03R01.csv (2 files -> 272 rows)\n",
      "Wrote derivatives/annotations/S01E03R02.csv (2 files -> 311 rows)\n",
      "Wrote derivatives/annotations/S01E03R03.csv (2 files -> 317 rows)\n",
      "Wrote derivatives/annotations/S01E03R04.csv (2 files -> 359 rows)\n",
      "Wrote derivatives/annotations/S01E03R05.csv (2 files -> 268 rows)\n",
      "Wrote derivatives/annotations/S01E03R06.csv (2 files -> 416 rows)\n",
      "Wrote derivatives/annotations/S01E04R01.csv (2 files -> 308 rows)\n",
      "Wrote derivatives/annotations/S01E04R02.csv (2 files -> 296 rows)\n",
      "Wrote derivatives/annotations/S01E04R03.csv (2 files -> 296 rows)\n",
      "Wrote derivatives/annotations/S01E04R04.csv (2 files -> 334 rows)\n",
      "Wrote derivatives/annotations/S01E04R05.csv (2 files -> 230 rows)\n",
      "\n",
      "Finished. Combined groups:\n",
      "  S01E01R01: 2 files -> derivatives/annotations/S01E01R01.csv\n",
      "  S01E01R02: 2 files -> derivatives/annotations/S01E01R02.csv\n",
      "  S01E01R03: 2 files -> derivatives/annotations/S01E01R03.csv\n",
      "  S01E02R01: 2 files -> derivatives/annotations/S01E02R01.csv\n",
      "  S01E02R02: 8 files -> derivatives/annotations/S01E02R02.csv\n",
      "  S01E02R03: 2 files -> derivatives/annotations/S01E02R03.csv\n",
      "  S01E02R04: 2 files -> derivatives/annotations/S01E02R04.csv\n",
      "  S01E02R05: 2 files -> derivatives/annotations/S01E02R05.csv\n",
      "  S01E02R06: 2 files -> derivatives/annotations/S01E02R06.csv\n",
      "  S01E02R07: 2 files -> derivatives/annotations/S01E02R07.csv\n",
      "  S01E03R01: 2 files -> derivatives/annotations/S01E03R01.csv\n",
      "  S01E03R02: 2 files -> derivatives/annotations/S01E03R02.csv\n",
      "  S01E03R03: 2 files -> derivatives/annotations/S01E03R03.csv\n",
      "  S01E03R04: 2 files -> derivatives/annotations/S01E03R04.csv\n",
      "  S01E03R05: 2 files -> derivatives/annotations/S01E03R05.csv\n",
      "  S01E03R06: 2 files -> derivatives/annotations/S01E03R06.csv\n",
      "  S01E04R01: 2 files -> derivatives/annotations/S01E04R01.csv\n",
      "  S01E04R02: 2 files -> derivatives/annotations/S01E04R02.csv\n",
      "  S01E04R03: 2 files -> derivatives/annotations/S01E04R03.csv\n",
      "  S01E04R04: 2 files -> derivatives/annotations/S01E04R04.csv\n",
      "  S01E04R05: 2 files -> derivatives/annotations/S01E04R05.csv\n"
     ]
    }
   ],
   "source": [
    "groups = find_annotation_files(ANNOT_DIR)\n",
    "\n",
    "summary = []\n",
    "for prefix, files in groups.items():\n",
    "    out = combine_group(prefix, files)\n",
    "    if out is None:\n",
    "        print(f\"No valid files for {prefix}\")\n",
    "        continue\n",
    "    merged, renamed = out\n",
    "    out_path = OUT_DIR / f\"{prefix}.csv\"\n",
    "    merged.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote {out_path} ({len(files)} files -> {len(merged)} rows)\")\n",
    "    summary.append((prefix, len(files), out_path))\n",
    "\n",
    "print(\"\\nFinished. Combined groups:\")\n",
    "for s in summary:\n",
    "    print(f\"  {s[0]}: {s[1]} files -> {s[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
