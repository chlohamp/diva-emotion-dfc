{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e84223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path as op\n",
    "import re\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee20f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/tr80j6dx7kz1xqvddnxtqtzr0000gn/T/ipykernel_88497/1480775116.py:2: DeprecationWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  from nilearn import datasets, masking, input_data\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for neuroimaging and atlas processing\n",
    "from nilearn import datasets, masking, input_data\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1f83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and plotting theme\n",
    "RELI_DIR = Path(\"dset/derivatives/caps/interrater\")\n",
    "FIGURES_DIR = Path(\"dset/derivatives/figures\")\n",
    "# will use loop later to run over all subjects\n",
    "OUT_DIR = Path(\"dset/derivatives/caps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321194f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Craddock 268 atlas...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nilearn.datasets' has no attribute 'fetch_craddock_2012'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Craddock 268 atlas\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading Craddock 268 atlas...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m craddock_atlas = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_craddock_2012\u001b[49m()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use the 268 ROI parcellation\u001b[39;00m\n\u001b[32m      6\u001b[39m atlas_filename = craddock_atlas[\u001b[33m'\u001b[39m\u001b[33mscorr_mean\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# 268 ROIs\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'nilearn.datasets' has no attribute 'fetch_craddock_2012'"
     ]
    }
   ],
   "source": [
    "# Load Craddock 268 atlas\n",
    "print(\"Loading Craddock 268 atlas...\")\n",
    "craddock_atlas = datasets.fetch_craddock_2012()\n",
    "\n",
    "# Use the 268 ROI parcellation\n",
    "atlas_filename = craddock_atlas['scorr_mean']  # 268 ROIs\n",
    "atlas_labels = craddock_atlas['labels']\n",
    "\n",
    "print(f\"Atlas loaded: {atlas_filename}\")\n",
    "print(f\"Number of ROIs: 268\")\n",
    "\n",
    "# Create masker for extracting time series from ROIs\n",
    "masker = input_data.NiftiLabelsMasker(\n",
    "    labels_img=atlas_filename,\n",
    "    standardize=False,  # We'll do our own z-scoring\n",
    "    memory='nilearn_cache',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0846047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING sub-Blossom\n",
      "============================================================\n",
      "\n",
      "Processing Episode 2 with 7 runs...\n",
      "  Processing run 1...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-1_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-1_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 2...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-2_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-2_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 3...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-3_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-3_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 4...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-4_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-4_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 5...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-5_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-5_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 6...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-6_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-6_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "  Processing run 7...\n",
      "    Extracting time series from sub-Blossom_ses-02_task-strangerthings_run-7_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz...\n",
      "    ERROR processing dset/sub-Blossom/ses-02/func/sub-Blossom_ses-02_task-strangerthings_run-7_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz: name 'masker' is not defined\n",
      "WARNING: No valid runs found for sub-Blossom\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================\n",
      "Processed 0 participants:\n"
     ]
    }
   ],
   "source": [
    "# Extract BOLD time series and create z-scored participant matrices\n",
    "\n",
    "# Define all runs for each participant and episode\n",
    "participant_data = {\n",
    "    \"sub-Blossom\": {\n",
    "        \"episode_2\": [1, 2, 3, 4, 5, 6, 7]  # Available runs for episode 2\n",
    "    }\n",
    "    # Add other participants as needed\n",
    "}\n",
    "\n",
    "# Initialize storage for participant-level matrices\n",
    "all_participant_matrices = {}\n",
    "\n",
    "for sub_id, episodes in participant_data.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING {sub_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    participant_timeseries = []\n",
    "    \n",
    "    for episode_key, run_numbers in episodes.items():\n",
    "        ep_num = int(episode_key.split('_')[1])\n",
    "        \n",
    "        print(f\"\\nProcessing Episode {ep_num} with {len(run_numbers)} runs...\")\n",
    "        \n",
    "        for run_num in run_numbers:\n",
    "            print(f\"  Processing run {run_num}...\")\n",
    "            \n",
    "            TASK_DIR = Path(f\"dset/{sub_id}/ses-{ep_num:02d}/func\") \n",
    "            \n",
    "            # Construct the filename - note that run number is NOT zero-padded\n",
    "            task_filename = f\"{sub_id}_ses-{ep_num:02d}_task-strangerthings_run-{run_num}_part-mag_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz\"\n",
    "            task_filepath = TASK_DIR / task_filename\n",
    "            \n",
    "            if not task_filepath.exists():\n",
    "                print(f\"    WARNING: File not found: {task_filepath}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Extract time series from 268 ROIs\n",
    "                print(f\"    Extracting time series from {task_filepath.name}...\")\n",
    "                time_series = masker.fit_transform(task_filepath)\n",
    "                \n",
    "                print(f\"    Time series shape: {time_series.shape} (TRs x ROIs)\")\n",
    "                \n",
    "                # Z-score normalization within each ROI across time points\n",
    "                # This normalizes by standard error (std/sqrt(n)) across fMRI volumes\n",
    "                print(\"    Applying z-score normalization...\")\n",
    "                \n",
    "                # Calculate z-scores: (x - mean) / std for each ROI\n",
    "                roi_means = np.mean(time_series, axis=0)\n",
    "                roi_stds = np.std(time_series, axis=0, ddof=1)  # Using sample std\n",
    "                \n",
    "                # Avoid division by zero for constant signals\n",
    "                roi_stds[roi_stds == 0] = 1.0\n",
    "                \n",
    "                # Z-score normalization\n",
    "                z_scored_ts = (time_series - roi_means) / roi_stds\n",
    "                \n",
    "                print(f\"    Z-scored time series shape: {z_scored_ts.shape}\")\n",
    "                print(f\"    Z-score stats - Mean: {np.mean(z_scored_ts):.4f}, Std: {np.std(z_scored_ts):.4f}\")\n",
    "                \n",
    "                # Store z-scored time series for this run\n",
    "                participant_timeseries.append(z_scored_ts)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR processing {task_filepath}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if participant_timeseries:\n",
    "        # Concatenate all runs for this participant\n",
    "        print(f\"\\nConcatenating {len(participant_timeseries)} runs for {sub_id}...\")\n",
    "        participant_matrix = np.vstack(participant_timeseries)\n",
    "        \n",
    "        print(f\"Final participant matrix shape: {participant_matrix.shape}\")\n",
    "        print(f\"  - Total TRs across all runs: {participant_matrix.shape[0]}\")\n",
    "        print(f\"  - Number of ROIs (Craddock 268): {participant_matrix.shape[1]}\")\n",
    "        \n",
    "        # Store the participant-level matrix\n",
    "        all_participant_matrices[sub_id] = participant_matrix\n",
    "        \n",
    "        # Save the participant matrix\n",
    "        output_dir = OUT_DIR / \"timeseries_matrices\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        output_file = output_dir / f\"{sub_id}_zscore_timeseries_matrix.npy\"\n",
    "        np.save(output_file, participant_matrix)\n",
    "        print(f\"Saved participant matrix to: {output_file}\")\n",
    "        \n",
    "        # Also save as CSV for easier inspection\n",
    "        output_csv = output_dir / f\"{sub_id}_zscore_timeseries_matrix.csv\"\n",
    "        df_matrix = pd.DataFrame(participant_matrix, \n",
    "                                columns=[f\"ROI_{i+1:03d}\" for i in range(participant_matrix.shape[1])])\n",
    "        df_matrix.to_csv(output_csv, index=False)\n",
    "        print(f\"Saved participant matrix (CSV) to: {output_csv}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"WARNING: No valid runs found for {sub_id}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Processed {len(all_participant_matrices)} participants:\")\n",
    "for sub_id, matrix in all_participant_matrices.items():\n",
    "    print(f\"  {sub_id}: {matrix.shape[0]} TRs Ã— {matrix.shape[1]} ROIs\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
